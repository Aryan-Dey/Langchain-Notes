{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c4bed8a",
   "metadata": {},
   "source": [
    "#### **Chains**  \n",
    "Chains are a way to connect multiple steps (components) into a pipeline.Each step’s output becomes the next step’s input, The entire flow becomes automated.  \n",
    "You only need to provide input to the first step, and LangChain handles the rest.\n",
    "\n",
    "**Why Use Chains?** \n",
    "1) Reduces repetitive code\n",
    "2) Improves modularity\n",
    "3) Automates end-to-end execution\n",
    "4) Easier to maintain and scale\n",
    "\n",
    "**Types of Chains**  \n",
    "**1) Sequential Chains** - Linear Steps, one after another(like a pipeline)  \n",
    "**2) Parallel Chains** - Multiple chains run at the same time (for parallel processing)  \n",
    "**3) Conditional Chains** - Based on Input, chains are triggered (like if/else logic flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13c5b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aryan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5695ead9",
   "metadata": {},
   "source": [
    "**Simple Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ad368e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are five interesting facts about cricket:\n",
      "\n",
      "1. **The longest game in history**: The longest cricket match in history was played between England and South Africa in 1939, lasting for 14 days. The game was eventually abandoned due to weather conditions and the fact that the English team had to catch a boat to return home.\n",
      "\n",
      "2. **The origins of the term \"over\"**: In cricket, an \"over\" refers to a set of six deliveries bowled by a bowler. The term originated from the fact that the umpire would call out \"over\" when the bowler had completed six deliveries, indicating that the bowler had to switch ends and the other team's bowler would take over.\n",
      "\n",
      "3. **The first cricket World Cup**: The first Cricket World Cup was held in 1975 in England, with eight teams participating. The West Indies won the tournament, defeating Australia in the final at Lord's Cricket Ground in London.\n",
      "\n",
      "4. **The fastest delivery in cricket history**: The fastest delivery in cricket history was bowled by Pakistani fast bowler Shoaib Akhtar, who clocked a speed of 161.3 km/h (100.2 mph) during a match against England in 2003. This delivery is still considered one of the fastest in the history of the game.\n",
      "\n",
      "5. **The highest individual score in cricket**: The highest individual score in cricket history was achieved by Brian Lara, a West Indian batsman, who scored 400 not out against England in 2004. Lara's record-breaking innings lasted for over 12 hours and helped the West Indies draw the match against England.\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Generate 5 interesting facts about {topic}\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | parser\n",
    "result = chain.invoke({'topic': 'cricket'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7978d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     +-------------+       \n",
      "     | PromptInput |       \n",
      "     +-------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "    +----------------+     \n",
      "    | PromptTemplate |     \n",
      "    +----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +----------+         \n",
      "      | ChatGroq |         \n",
      "      +----------+         \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii() # Visualize the chain (requires grandalf) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921a22a5",
   "metadata": {},
   "source": [
    "##### **Sequential Chains**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a56d9b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Detailed Summary: Indian Political Scenario: An Overview**\n",
      "\n",
      "The Indian political landscape is a complex and dynamic system, shaped by the country's rich history, diverse culture, and the aspirations of its 1.3 billion people. As the world's largest democracy, India has a unique system of governance, with a parliamentary form of government and a federal structure. This report provides an in-depth analysis of the current Indian political scenario, including major political parties, key issues, emerging trends, and state-level politics.\n",
      "\n",
      "**Major Political Parties:**\n",
      "\n",
      "The report highlights the following major political parties in India:\n",
      "\n",
      "1. **Bharatiya Janata Party (BJP)**: The ruling party at the Center, led by Prime Minister Narendra Modi, which has been in power since 2014.\n",
      "2. **Indian National Congress (INC)**: The main opposition party, led by President Rahul Gandhi, which has a strong presence in several states.\n",
      "3. **All India Trinamool Congress (AITC)**: A regional party based in West Bengal, led by Mamata Banerjee, which has a significant presence in national politics.\n",
      "4. **Bahujan Samaj Party (BSP)**: A regional party based in Uttar Pradesh, led by Mayawati, which has a significant presence in the state and national politics.\n",
      "\n",
      "**Key Issues:**\n",
      "\n",
      "The report identifies the following key issues in Indian politics:\n",
      "\n",
      "1. **Economic Growth**: India's economy has been growing rapidly, but the country still faces significant challenges, including high levels of poverty and inequality.\n",
      "2. **Unemployment**: Unemployment is a major concern, with millions of young people entering the workforce every year, and the government has launched initiatives to create jobs.\n",
      "3. **National Security**: National security is a key issue, with India facing threats from neighboring countries, including Pakistan and China, and the government has taken steps to strengthen defense capabilities.\n",
      "4. **Social Justice**: Social justice is a major concern, with the country facing significant challenges related to caste, gender, and religion, and the government has launched initiatives to promote social justice.\n",
      "\n",
      "**Emerging Trends:**\n",
      "\n",
      "The report highlights the following emerging trends in Indian politics:\n",
      "\n",
      "1. **Rise of Regional Parties**: Regional parties have been gaining strength, with several parties emerging as key players in national politics.\n",
      "2. **Growing Importance of Social Media**: Social media has become an important tool in Indian politics, with parties using platforms to connect with voters and promote policies.\n",
      "3. **Increasing Focus on Nationalism**: Nationalism has become a key issue, with several parties promoting a strong nationalist agenda.\n",
      "4. **Growing Concerns about Environmental Issues**: Environmental issues, including climate change and pollution, have become a major concern, with several parties promoting a greener agenda.\n",
      "\n",
      "**State-Level Politics:**\n",
      "\n",
      "The report provides an overview of the political landscape in several key states, including:\n",
      "\n",
      "1. **Uttar Pradesh**: The BJP has been in power since 2017, with Yogi Adityanath as the Chief Minister, and the state is a key battleground in Indian politics.\n",
      "2. **West Bengal**: The AITC has been in power since 2011, with Mamata Banerjee as the Chief Minister, and the state is a key bastion of the party.\n",
      "3. **Maharashtra**: The BJP has been in power since 2014, with Devendra Fadnavis as the Chief Minister, and the state is a key economic hub.\n",
      "4. **Tamil Nadu**: The AIADMK has been in power since 2016, with Edappadi K. Palaniswami as the Chief Minister, and the state is a key battleground in Indian politics.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "The Indian political scenario is complex and dynamic, with several parties and issues vying for attention. The BJP has been in power at the Center since 2014, but faces significant challenges, including the rise of regional parties and growing concerns about economic growth and social justice. The report concludes that the Indian political scenario is likely to remain fluid and unpredictable, with several parties and issues emerging as key players.\n",
      "\n",
      "**Recommendations:**\n",
      "\n",
      "The report provides the following recommendations:\n",
      "\n",
      "1. **Promote Economic Growth**: The government should focus on promoting economic growth, including investing in infrastructure and promoting foreign investment.\n",
      "2. **Address Unemployment**: The government should launch initiatives to address unemployment, including creating jobs in key sectors.\n",
      "3. **Strengthen National Security**: The government should strengthen national security, including investing in defense capabilities and promoting international cooperation.\n",
      "4. **Promote Social Justice**: The government should promote social justice, including launching initiatives to address issues like caste, gender, and religion.\n",
      "\n",
      "**Future Outlook:**\n",
      "\n",
      "The report concludes that the Indian political scenario is likely to remain dynamic and unpredictable, with several parties and issues emerging as key players. The next general election is likely to be a key turning point, with several parties vying for power. As the country continues to grow and develop, the Indian political scenario is likely to remain a key area of focus, with significant implications for the country's future.\n"
     ]
    }
   ],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    template=\"Generate a detailed report about the {topic}\",\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template=\"Generate a detailed summary of the report {text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain1 = prompt1 | model | parser | prompt2 | model | parser\n",
    "result = chain1.invoke({'topic': 'Indian Political Scenario'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d005dd8e",
   "metadata": {},
   "source": [
    "##### **Parallel Chains**\n",
    "Uses the concept of Runnable Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f6afc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Support Vector Machines (SVMs) Notes and Quiz**\n",
      "=====================================================\n",
      "\n",
      "### Advantages of SVMs\n",
      "\n",
      "1. **Effective in high dimensional spaces**: SVMs remain effective even when the number of dimensions exceeds the number of samples.\n",
      "2. **Memory efficient**: SVMs use only a subset of training points—support vectors—in the decision function, making them memory efficient.\n",
      "3. **Versatile with different kernel functions**: SVMs can be used with various kernel functions, allowing for flexibility in modeling different types of data.\n",
      "4. **Works well with limited samples**: SVMs can perform well even with a limited number of samples.\n",
      "\n",
      "### Disadvantages of SVMs\n",
      "\n",
      "1. **Over-fitting possible with many features**: SVMs can suffer from over-fitting when dealing with a large number of features.\n",
      "2. **No direct probability estimates**: SVMs do not provide direct probability estimates, requiring additional methods for estimation.\n",
      "3. **Requires specific data format for optimal performance**: SVMs require a specific data format for optimal performance, which can be a limitation.\n",
      "\n",
      "### Quiz\n",
      "\n",
      "**1. Q:** What are the main uses of Support Vector Machines (SVMs)?  \n",
      "**A:** Classification, regression, and outlier detection.\n",
      "\n",
      "**2. Q:** Why are SVMs considered memory efficient?  \n",
      "**A:** They use only a subset of training points—support vectors—in the decision function.\n",
      "\n",
      "**3. Q:** What is a key advantage of SVMs in high‑dimensional data?  \n",
      "**A:** They remain effective even when the number of dimensions exceeds the number of samples.\n",
      "\n",
      "**4. Q:** What is a major drawback of SVMs regarding probability estimates?  \n",
      "**A:** They don’t provide probabilities directly; estimating them requires costly five‑fold cross‑validation.\n",
      "\n",
      "**5. Q:** Which data formats does scikit‑learn’s SVM accept for training and prediction?  \n",
      "**A:** Dense `numpy.ndarray` (C‑ordered, `float64`) or sparse `scipy.sparse.csr_matrix` (also `float64`).\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "    template=\"Generate short & simple notes from the following text: \\n {text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template=\"Generate 5 short question answers from the following text: \\n {text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "prompt3 = PromptTemplate(\n",
    "    template=\"Merge the provided notes and quiz into a single document \\n notes -> {notes} and quiz -> {quiz}\",\n",
    "    input_variables=['notes', 'quiz']\n",
    ")\n",
    "\n",
    "model1 = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "model2 = ChatGroq(model=\"openai/gpt-oss-20b\")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"notes\": prompt1 | model1 | parser,\n",
    "    \"quiz\": prompt2 | model2 | parser\n",
    "})\n",
    "\n",
    "merge_chain = prompt3 | model1 | parser\n",
    "\n",
    "chain = parallel_chain | merge_chain\n",
    "\n",
    "text = \"\"\"\n",
    "Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.\n",
    "\n",
    "The advantages of support vector machines are:\n",
    "\n",
    "Effective in high dimensional spaces.\n",
    "\n",
    "Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "\n",
    "Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "\n",
    "Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "The disadvantages of support vector machines include:\n",
    "\n",
    "If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\n",
    "\n",
    "SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below).\n",
    "\n",
    "The support vector machines in scikit-learn support both dense (numpy.ndarray and convertible to that by numpy.asarray) and sparse (any scipy.sparse) sample vectors as input. However, to use an SVM to make predictions for sparse data, it must have been fit on such data. For optimal performance, use C-ordered numpy.ndarray (dense) or scipy.sparse.csr_matrix (sparse) with dtype=float64.\n",
    "\"\"\"\n",
    "\n",
    "result = chain.invoke({'text': text})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3492d8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          +---------------------------+            \n",
      "          | Parallel<notes,quiz>Input |            \n",
      "          +---------------------------+            \n",
      "                ***             ***                \n",
      "              **                   **              \n",
      "            **                       **            \n",
      "+----------------+              +----------------+ \n",
      "| PromptTemplate |              | PromptTemplate | \n",
      "+----------------+              +----------------+ \n",
      "          *                             *          \n",
      "          *                             *          \n",
      "          *                             *          \n",
      "    +----------+                  +----------+     \n",
      "    | ChatGroq |                  | ChatGroq |     \n",
      "    +----------+                  +----------+     \n",
      "          *                             *          \n",
      "          *                             *          \n",
      "          *                             *          \n",
      "+-----------------+            +-----------------+ \n",
      "| StrOutputParser |            | StrOutputParser | \n",
      "+-----------------+            +-----------------+ \n",
      "                ***             ***                \n",
      "                   **         **                   \n",
      "                     **     **                     \n",
      "          +----------------------------+           \n",
      "          | Parallel<notes,quiz>Output |           \n",
      "          +----------------------------+           \n",
      "                         *                         \n",
      "                         *                         \n",
      "                         *                         \n",
      "                +----------------+                 \n",
      "                | PromptTemplate |                 \n",
      "                +----------------+                 \n",
      "                         *                         \n",
      "                         *                         \n",
      "                         *                         \n",
      "                   +----------+                    \n",
      "                   | ChatGroq |                    \n",
      "                   +----------+                    \n",
      "                         *                         \n",
      "                         *                         \n",
      "                         *                         \n",
      "                +-----------------+                \n",
      "                | StrOutputParser |                \n",
      "                +-----------------+                \n",
      "                         *                         \n",
      "                         *                         \n",
      "                         *                         \n",
      "            +-----------------------+              \n",
      "            | StrOutputParserOutput |              \n",
      "            +-----------------------+              \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6801b",
   "metadata": {},
   "source": [
    "##### **Conditional Chain**  \n",
    "Uses Runnable branch - format ->  \n",
    "    RunnableBranch(  \n",
    "        (condition1, chain1),  \n",
    "        (condition2, chain2),\n",
    "        default chain  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b45cdfde",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected mapping type as input to PromptTemplate. Received <class '__main__.Feedback'>.\nFor troubleshooting, visit: https://docs.langchain.com/oss/python/langchain/errors/INVALID_PROMPT_INPUT ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 46\u001b[0m\n\u001b[0;32m     38\u001b[0m conditional_chain \u001b[38;5;241m=\u001b[39m RunnableBranch(\n\u001b[0;32m     39\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msentiment \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m, prompt2 \u001b[38;5;241m|\u001b[39m model \u001b[38;5;241m|\u001b[39m parser1),\n\u001b[0;32m     40\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msentiment \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m, prompt3 \u001b[38;5;241m|\u001b[39m model \u001b[38;5;241m|\u001b[39m parser1),\n\u001b[0;32m     41\u001b[0m     RunnableLambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not understand the feedback\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     44\u001b[0m chain \u001b[38;5;241m=\u001b[39m classifier_chain \u001b[38;5;241m|\u001b[39m conditional_chain\n\u001b[1;32m---> 46\u001b[0m result1 \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeedback\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mThe product is great and I love it!\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(result1)\n\u001b[0;32m     49\u001b[0m result2 \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeedback\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe product is not good and I hate it!\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[1;32mc:\\Users\\Aryan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3129\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3127\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3128\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3129\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3130\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3131\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Aryan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\branch.py:224\u001b[0m, in \u001b[0;36mRunnableBranch.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m     expression_value \u001b[38;5;241m=\u001b[39m condition\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    217\u001b[0m         config\u001b[38;5;241m=\u001b[39mpatch_config(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m         ),\n\u001b[0;32m    221\u001b[0m     )\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m expression_value:\n\u001b[1;32m--> 224\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mrunnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbranch:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43midx\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Aryan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3127\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3125\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   3126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3127\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3128\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3129\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config)\n",
      "File \u001b[1;32mc:\\Users\\Aryan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\prompts\\base.py:215\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[0;32m    214\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Aryan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2050\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   2046\u001b[0m     child_config \u001b[38;5;241m=\u001b[39m patch_config(config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child())\n\u001b[0;32m   2047\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   2048\u001b[0m         output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   2049\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 2050\u001b[0m             \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2051\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   2052\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2054\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2055\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2056\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2057\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2058\u001b[0m         )\n\u001b[0;32m   2059\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2060\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\Aryan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    427\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Aryan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\prompts\\base.py:188\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m--> 188\u001b[0m     inner_input_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_input_)\n",
      "File \u001b[1;32mc:\\Users\\Aryan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\prompts\\base.py:164\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    160\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected mapping type as input to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(inner_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         )\n\u001b[1;32m--> 164\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    165\u001b[0m             create_message(\n\u001b[0;32m    166\u001b[0m                 message\u001b[38;5;241m=\u001b[39mmsg, error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mINVALID_PROMPT_INPUT\n\u001b[0;32m    167\u001b[0m             )\n\u001b[0;32m    168\u001b[0m         )\n\u001b[0;32m    169\u001b[0m missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_variables)\u001b[38;5;241m.\u001b[39mdifference(inner_input)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected mapping type as input to PromptTemplate. Received <class '__main__.Feedback'>.\nFor troubleshooting, visit: https://docs.langchain.com/oss/python/langchain/errors/INVALID_PROMPT_INPUT "
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableBranch, RunnableLambda\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "parser1 = StrOutputParser()\n",
    "\n",
    "class Feedback(BaseModel):\n",
    "\n",
    "    sentiment: Literal['positive', 'negative'] = Field(description=\"The sentiment of the feedback\")\n",
    "\n",
    "parser2 = PydanticOutputParser(pydantic_object=Feedback)\n",
    "\n",
    "# We want the LLM model to return only positive or negative sentiment that's why we are using PydanticOutputParser\n",
    "prompt1 = PromptTemplate(\n",
    "    template=\"Classify the sentiment of the following feedback text into postive or negative \\n {feedback} \\n {format_instruction}\",\n",
    "    input_variables=['feedback'],\n",
    "    partial_variables={'format_instruction': parser2.get_format_instructions()}\n",
    ")\n",
    "\n",
    "classifier_chain = prompt1 | model | parser2\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template = \"Write an appropriate response to this positive feedback: \\n {feedback} \\n {format_instruction}\",\n",
    "    input_variables=['feedback'],\n",
    ")\n",
    "\n",
    "# positive_chain = prompt2 | model | parser1\n",
    "\n",
    "prompt3 = PromptTemplate(\n",
    "    template = \"Write an appropriate response to this negative feedback: \\n {feedback} \\n {format_instruction}\",\n",
    "    input_variables=['feedback'],\n",
    ")\n",
    "\n",
    "# negative_chain = prompt3 | model | parser1\n",
    "\n",
    "conditional_chain = RunnableBranch(\n",
    "    (lambda x: x.sentiment == 'positive', prompt2 | model | parser1),\n",
    "    (lambda x: x.sentiment == 'negative', prompt3 | model | parser1),\n",
    "    RunnableLambda(lambda x: \"Could not understand the feedback\")\n",
    ")\n",
    "\n",
    "chain = classifier_chain | conditional_chain\n",
    "\n",
    "result1 = chain.invoke({'feedback': 'The product is great and I love it!'})\n",
    "print(result1)\n",
    "\n",
    "result2 = chain.invoke({'feedback': 'The product is not good and I hate it!'})\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c377df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you so much for your kind words. We're thrilled to hear that you're happy with our service. Your satisfaction is our top priority, and we're glad we could meet your expectations. If you have any other questions or need further assistance, don't hesitate to reach out. We appreciate your feedback and look forward to serving you again in the future.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnableBranch, RunnableLambda\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "class Feedback(BaseModel):\n",
    "\n",
    "    sentiment: Literal['positive','negative'] = Field(description='Give the sentiment of the feedback')\n",
    "\n",
    "parser2 = PydanticOutputParser(pydantic_object=Feedback)\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "    template='Classify the sentiment of the following feedback text into postive or negative \\n {feedback} \\n {format_instruction}',\n",
    "    input_variables=['feedback'],\n",
    "    partial_variables={'format_instruction':parser2.get_format_instructions()}\n",
    ")\n",
    "\n",
    "classifier_chain = prompt1 | model | parser2\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template='Write an appropriate response to this positive feedback \\n {feedback}',\n",
    "    input_variables=['feedback']\n",
    ")\n",
    "\n",
    "prompt3 = PromptTemplate(\n",
    "    template='Write an appropriate response to this negative feedback \\n {feedback}',\n",
    "    input_variables=['feedback']\n",
    ")\n",
    "\n",
    "branch_chain = RunnableBranch(\n",
    "    (lambda x:x.sentiment == 'positive', prompt2 | model | parser),\n",
    "    (lambda x:x.sentiment == 'negative', prompt3 | model | parser),\n",
    "    RunnableLambda(lambda x: \"could not find sentiment\")\n",
    ")\n",
    "\n",
    "chain = classifier_chain | branch_chain\n",
    "\n",
    "print(chain.invoke({'feedback': 'This is a beautiful phone'}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
