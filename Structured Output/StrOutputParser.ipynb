{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5053857",
   "metadata": {},
   "source": [
    "#### **Output Parsers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d03262",
   "metadata": {},
   "source": [
    "**Why Use a Parser at All?**\n",
    "\n",
    "Even when a model gives a text response, it also includes metadata like token usage, response time, etc. Without a parser, you often have to manually extract just the content using result.content.\n",
    "\n",
    "➡️ Problem: Manually extracting .content every time is tedious.\n",
    "\n",
    "➡️ Solution: StringOutputParser automates this. It extracts the core text and makes it clean and usable in chains or further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589294fb",
   "metadata": {},
   "source": [
    "**Goal:**\n",
    "\n",
    "Use LLM twice:  \n",
    "Generate a detailed report on a topic (e.g., Black Hole).  \n",
    "Then use that report to generate a 5-line summary.  \n",
    "\n",
    "Two methods shown:  \n",
    "**Without parser →** using result.content manually  \n",
    "**With StringOutputParser →** cleaner & reusable via Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfe47ce",
   "metadata": {},
   "source": [
    "##### **Without Parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bb07cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a 5-line summary of the report: Black holes are regions in space with\n",
      "incredibly strong gravitational pull, formed when massive stars collapse.  They\n",
      "are characterized by their event horizon, singularity, and ergosphere, and come\n",
      "in four types: stellar, intermediate-mass, supermassive, and primordial.  Black\n",
      "holes have unique properties, including their gravitational pull, Hawking\n",
      "radiation, and ability to warp spacetime.  Their presence can be inferred\n",
      "through observational evidence such as X-rays, radio waves, and gravitational\n",
      "lensing.  Despite significant research, many challenges and open questions\n",
      "remain, including the information paradox and the nature of singularities, which\n",
      "continue to be the subject of ongoing study and research.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id=\"google/gemma-2-2b-it\",\n",
    "#     task = \"text-generation\",\n",
    "#     huggingfacehub_api_token=os.getenv(\"HUGGINGFACE_API_TOKEN\")\n",
    "# )\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "# 1st Prompt -> Detailed Report\n",
    "template1 = PromptTemplate(\n",
    "    template=\"Write a detailed report on {topic}.\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "# 2nd Prompt -> Summary\n",
    "template2 = PromptTemplate(\n",
    "    template=\"Write a 5-line summary of the following report: {text}\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "prompt1 = template1.invoke({\"topic\":\"Black Hole\"})\n",
    "result1 = model.invoke(prompt1)\n",
    "\n",
    "prompt2 = template2.invoke({\"text\":result1.content})\n",
    "result2 = model.invoke(prompt2)\n",
    "\n",
    "wrapped_output = textwrap.fill(result2.content, width=80)\n",
    "print(wrapped_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fbbf2e",
   "metadata": {},
   "source": [
    "##### **Using StrOutputParser with Chains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d9ddc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a 5-point summary of the report on black holes:\n",
      "\n",
      "1. **Formation of Black Holes**: Black holes are formed when a massive star collapses in on itself, causing a massive amount of matter to be compressed into an incredibly small space, creating an intense gravitational field that warps spacetime. There are four types of black holes, including stellar, supermassive, intermediate-mass, and primordial black holes.\n",
      "\n",
      "2. **Properties of Black Holes**: Black holes have unique properties, including an event horizon (the point of no return), a singularity (the point at the center with infinite density and gravity), an ergosphere (a region where gravity can extract energy from objects), and Hawking radiation (radiation emitted due to quantum effects near the event horizon).\n",
      "\n",
      "3. **Effects of Black Holes on Spacetime**: Black holes have a profound impact on spacetime, causing gravitational lensing (bending and distorting light), frame-dragging (twisting and rotating spacetime), and time dilation (slowing down time near the black hole).\n",
      "\n",
      "4. **Observational Evidence for Black Holes**: While black holes themselves are invisible, their presence can be inferred by observing the effects they have on the surrounding environment, including X-rays and gamma rays emitted by hot gas, radio waves emitted by matter spiraling into the black hole, star motions, and gravitational waves.\n",
      "\n",
      "5. **Future Research Directions**: Ongoing and future research will focus on imaging black holes in greater detail, detecting more gravitational waves to learn about black hole mergers, and understanding how black holes form and evolve over cosmic time, with the aim of revealing new and exciting insights into these mysterious objects.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import textwrap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "# 1st Prompt -> Detailed Report\n",
    "template1 = PromptTemplate(\n",
    "    template=\"Write a detailed report on {topic}.\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "# 2nd Prompt -> Summary\n",
    "template2 = PromptTemplate(\n",
    "    template=\"Write a 5-point summary of the following report: {text}\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = template1 | model | parser | template2 | model | parser\n",
    "\n",
    "result = chain.invoke({'topic':'Black Hole'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af268e3f",
   "metadata": {},
   "source": [
    "##### **JSON Output Parsers**  \n",
    "Forces the LLM to return output in valid JSON format – clean, structured, and easy to work with in Python (as dictionaries).  \n",
    "\n",
    "**Limitation of JsonOutputParser-**  \n",
    "❌ It does NOT enforce a schema (i.e. might not give in a definative format which we want ).   \n",
    "Eg- Change template - 'Give me 5 facts about {topic} \\n {format_instruction}'\n",
    "You can ask for specific fields, but LLM might return a slightly different format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f49f973a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Emily Wilson', 'age': 32, 'city': 'New York'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"Give me the name, age, and city of a fictional person \\n {format_instructions}\",\n",
    "    input_variables=[],  # Empty list because we're not using any input variables \n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}  # Passes the format instructions to the template\n",
    ")\n",
    "\n",
    "chain = template | model | parser\n",
    "\n",
    "result = chain.invoke({})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccada84d",
   "metadata": {},
   "source": [
    "##### **Pydantic Output Parser**  \n",
    "PydanticOutputParser is an output parser in LangChain that uses Pydantic models to:  \n",
    "1) Enforce strict JSON schema  \n",
    "2) Validate data types  \n",
    "3) Apply constraints (e.g., age > 18)  \n",
    "4) Auto-convert incorrect types when possible  \n",
    "It is basically an upgraded StructuredOutputParser with validation + type safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d65a18f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='Give me the name, age, and city of a fictional person from India \\n The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"description\": \"The name of the person\", \"title\": \"Name\", \"type\": \"string\"}, \"age\": {\"description\": \"The age of the person must be greater than 18\", \"exclusiveMinimum\": 18, \"title\": \"Age\", \"type\": \"integer\"}, \"place\": {\"description\": \"The place where the person lives\", \"title\": \"Place\", \"type\": \"string\"}}, \"required\": [\"name\", \"age\", \"place\"]}\\n```'\n",
      "\n",
      "\n",
      "name='Nimal Perera' age=30 place='Colombo'\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "# Schema\n",
    "class Person(BaseModel):\n",
    "\n",
    "    name: str = Field(description=\"The name of the person\")\n",
    "    age: int = Field(gt=18, description=\"The age of the person must be greater than 18\")\n",
    "    place: str = Field(description=\"The place where the person lives\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Person)\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"Give me the name, age, and city of a fictional person from {country} \\n {format_instructions}\",\n",
    "    input_variables=[\"country\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "prompt = template.invoke({\"country\":\"India\"})\n",
    "print(prompt) # Prompt going to the LLM model BTS\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "chain = template | model | parser\n",
    "result = chain.invoke({'country': \"Sri Lanka\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50fbdfa",
   "metadata": {},
   "source": [
    "##### **Structured Output Parsers-** Deprecated Library \n",
    "forces the LLM to output structured JSON using a pre-defined schema.  \n",
    "This schema is declared using the ResponseSchema class.  \n",
    "**Main Benefit:** You enforce the structure of the LLM response (specific keys like fact1, fact2, etc.).    \n",
    "**Limitation -** It does not perform data validation (like data types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8142e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "schema = [\n",
    "    ResponseSchema(name=\"Fact 1\", description=\"Fact 1 about the topic\"),\n",
    "    ResponseSchema(name=\"Fact 2\", description=\"Fact 2 about the topic\"),\n",
    "    ResponseSchema(name=\"Fact 3\", description=\"Fact 3 about the topic\"),\n",
    "    ResponseSchema(name=\"Fact 4\", description=\"Fact 4 about the topic\"),\n",
    "    ResponseSchema(name=\"Fact 5\", description=\"Fact 5 about the topic\")\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(schema)\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template = \"Give me 5 facts about {topic} \\n {format_instructions}\",\n",
    "    input_variables = [\"topic\"],\n",
    "    partial_variables = {\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = template | model | parser\n",
    "result = chain.invoke({\"topic\":\"Black Hole\"})\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
